{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9f0731b",
   "metadata": {},
   "source": [
    "# Titanic Survival Prediction Model - Logistic Regression\n",
    "\n",
    "This notebook builds a machine learning model to predict whether a passenger survived the Titanic disaster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae5acf8",
   "metadata": {},
   "source": [
    "## 1. Load and Explore the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7dcb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5416e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Titanic dataset\n",
    "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "print(\"\\nDataset Info:\")\n",
    "print(df.info())\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\nStatistical Summary:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02cd48a",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29af9353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant features and target variable\n",
    "# Features: Pclass, Sex, Age, SibSp, Fare (5 features as required)\n",
    "features_to_use = ['Pclass', 'Sex', 'Age', 'SibSp', 'Fare']\n",
    "target = 'Survived'\n",
    "\n",
    "# Create a working copy\n",
    "df_working = df[features_to_use + [target]].copy()\n",
    "\n",
    "print(\"Working dataset shape:\", df_working.shape)\n",
    "print(\"\\nMissing values in selected features:\")\n",
    "print(df_working.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6306bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "# Fill Age with median\n",
    "df_working['Age'].fillna(df_working['Age'].median(), inplace=True)\n",
    "\n",
    "# Fill Fare with median\n",
    "df_working['Fare'].fillna(df_working['Fare'].median(), inplace=True)\n",
    "\n",
    "# Drop any remaining rows with missing values\n",
    "df_working.dropna(inplace=True)\n",
    "\n",
    "print(\"Missing values after handling:\")\n",
    "print(df_working.isnull().sum())\n",
    "print(\"\\nDataset shape after cleaning:\", df_working.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b82fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variable (Sex)\n",
    "# Male = 1, Female = 0\n",
    "df_working['Sex'] = df_working['Sex'].map({'male': 1, 'female': 0})\n",
    "\n",
    "print(\"Data after encoding categorical variables:\")\n",
    "print(df_working.head())\n",
    "print(\"\\nData types:\")\n",
    "print(df_working.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e4f60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features (X) and target (y)\n",
    "X = df_working[['Pclass', 'Sex', 'Age', 'SibSp', 'Fare']]\n",
    "y = df_working[target]\n",
    "\n",
    "print(\"Features shape:\", X.shape)\n",
    "print(\"Target shape:\", y.shape)\n",
    "print(\"\\nTarget distribution:\")\n",
    "print(y.value_counts())\n",
    "print(\"\\nTarget proportions:\")\n",
    "print(y.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe275b0b",
   "metadata": {},
   "source": [
    "## 3. Split Data into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9327ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Training set size:\", X_train.shape[0])\n",
    "print(\"Testing set size:\", X_test.shape[0])\n",
    "print(\"\\nTraining set target distribution:\")\n",
    "print(y_train.value_counts())\n",
    "print(\"\\nTesting set target distribution:\")\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b88e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling (standardization)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Scaled training data shape:\", X_train_scaled.shape)\n",
    "print(\"Scaled testing data shape:\", X_test_scaled.shape)\n",
    "print(\"\\nScaled data sample (first 5 rows):\")\n",
    "print(X_train_scaled[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54f1752",
   "metadata": {},
   "source": [
    "## 4. Build and Train a Machine Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce41c448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train the Logistic Regression model\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Model trained successfully!\")\n",
    "print(\"\\nModel coefficients:\")\n",
    "for feature, coef in zip(['Pclass', 'Sex', 'Age', 'SibSp', 'Fare'], model.coef_[0]):\n",
    "    print(f\"{feature}: {coef:.4f}\")\n",
    "print(f\"\\nIntercept: {model.intercept_[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cdbd20",
   "metadata": {},
   "source": [
    "## 5. Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6f2839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on training and testing data\n",
    "y_train_pred = model.predict(X_train_scaled)\n",
    "y_test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate accuracy\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"MODEL PERFORMANCE EVALUATION\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nTraining Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Testing Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed1da55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed classification report for test set\n",
    "print(\"\\nClassification Report (Test Set):\")\n",
    "print(\"=\"*50)\n",
    "print(classification_report(y_test, y_test_pred, \n",
    "                          target_names=['Did Not Survive', 'Survived']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72a084e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "print(\"\\nConfusion Matrix (Test Set):\")\n",
    "print(\"=\"*50)\n",
    "print(cm)\n",
    "print(\"\\nInterpretation:\")\n",
    "print(f\"True Negatives (Did not survive, predicted did not survive): {cm[0, 0]}\")\n",
    "print(f\"False Positives (Did not survive, predicted survived): {cm[0, 1]}\")\n",
    "print(f\"False Negatives (Survived, predicted did not survive): {cm[1, 0]}\")\n",
    "print(f\"True Positives (Survived, predicted survived): {cm[1, 1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58b2735",
   "metadata": {},
   "source": [
    "## 6. Save the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bf6130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model using joblib\n",
    "model_path = 'titanic_survival_model.pkl'\n",
    "joblib.dump(model, model_path)\n",
    "print(f\"Model saved successfully to {model_path}\")\n",
    "\n",
    "# Save the scaler as well (important for preprocessing new data)\n",
    "scaler_path = 'scaler.pkl'\n",
    "joblib.dump(scaler, scaler_path)\n",
    "print(f\"Scaler saved successfully to {scaler_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5795a519",
   "metadata": {},
   "source": [
    "## 7. Verify Model Reloading and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d8746f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the model to demonstrate it works without retraining\n",
    "loaded_model = joblib.load(model_path)\n",
    "loaded_scaler = joblib.load(scaler_path)\n",
    "\n",
    "print(\"Models reloaded successfully!\")\n",
    "\n",
    "# Test the reloaded model on the same test data\n",
    "y_test_pred_reloaded = loaded_model.predict(loaded_scaler.transform(X_test))\n",
    "reloaded_accuracy = accuracy_score(y_test, y_test_pred_reloaded)\n",
    "\n",
    "print(f\"\\nAccuracy with reloaded model: {reloaded_accuracy:.4f}\")\n",
    "print(\"Model reloading verified successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37dc6ed",
   "metadata": {},
   "source": [
    "## 8. Make Predictions on New Passenger Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6739d179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Predict survival for new passengers\n",
    "# Format: [Pclass, Sex (1=Male, 0=Female), Age, SibSp, Fare]\n",
    "\n",
    "new_passengers = pd.DataFrame([\n",
    "    [1, 0, 35, 1, 512.3292],      # 1st class female, 35, with 1 sibling, expensive ticket\n",
    "    [3, 1, 25, 0, 7.75],          # 3rd class male, 25, no siblings, cheap ticket\n",
    "    [2, 1, 40, 2, 21.0],          # 2nd class male, 40, with 2 siblings, moderate fare\n",
    "], columns=['Pclass', 'Sex', 'Age', 'SibSp', 'Fare'])\n",
    "\n",
    "# Scale the new data\n",
    "new_passengers_scaled = loaded_scaler.transform(new_passengers)\n",
    "\n",
    "# Make predictions\n",
    "predictions = loaded_model.predict(new_passengers_scaled)\n",
    "probabilities = loaded_model.predict_proba(new_passengers_scaled)\n",
    "\n",
    "print(\"\\nPredictions for New Passengers:\")\n",
    "print(\"=\"*70)\n",
    "for i, (_, row) in enumerate(new_passengers.iterrows()):\n",
    "    survival_status = \"SURVIVED\" if predictions[i] == 1 else \"DID NOT SURVIVE\"\n",
    "    survival_prob = probabilities[i][predictions[i]] * 100\n",
    "    print(f\"\\nPassenger {i+1}:\")\n",
    "    print(f\"  Class: {int(row['Pclass'])}, Sex: {'Male' if row['Sex']==1 else 'Female'}, Age: {row['Age']}, Siblings: {int(row['SibSp'])}, Fare: {row['Fare']:.2f}\")\n",
    "    print(f\"  Prediction: {survival_status} (Confidence: {survival_prob:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63b8a32",
   "metadata": {},
   "source": [
    "# Titanic Survival Prediction System\n",
    "## Model Development\n",
    "**Name:** Onafowokan Testament\n",
    "\n",
    "**Matric:** 21cg029905\n",
    "\n",
    "**Algorithm:** Logistic Regression\n",
    "\n",
    "**Features Used:** Pclass, Sex, Age, Fare, Embarked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03053d06",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147c83c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print('All libraries imported successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e95781",
   "metadata": {},
   "source": [
    "## 2. Load the Titanic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc43353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Titanic dataset\n",
    "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "print('Dataset shape:', df.shape)\n",
    "print('\\nFirst few rows:')\n",
    "print(df.head())\n",
    "print('\\nDataset Info:')\n",
    "print(df.info())\n",
    "print('\\nMissing Values:')\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e33d4a5",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987342d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features and target variable\n",
    "features = ['Pclass', 'Sex', 'Age', 'Fare', 'Embarked']\n",
    "X = df[features].copy()\n",
    "y = df['Survived'].copy()\n",
    "\n",
    "print('Selected Features:', features)\n",
    "print('Target Variable: Survived')\n",
    "print('\\nDataset shape - X:', X.shape, 'y:', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43196141",
   "metadata": {},
   "source": [
    "### 3a. Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3e6677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print('Missing values before handling:')\n",
    "print(X.isnull().sum())\n",
    "\n",
    "# Handle missing values\n",
    "# Age: fill with median\n",
    "X['Age'].fillna(X['Age'].median(), inplace=True)\n",
    "\n",
    "# Embarked: fill with mode\n",
    "X['Embarked'].fillna(X['Embarked'].mode()[0], inplace=True)\n",
    "\n",
    "# Fare: fill with median\n",
    "X['Fare'].fillna(X['Fare'].median(), inplace=True)\n",
    "\n",
    "print('\\nMissing values after handling:')\n",
    "print(X.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddc4aed",
   "metadata": {},
   "source": [
    "### 3b & 3c. Encode Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10352737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy for encoding\n",
    "X_encoded = X.copy()\n",
    "\n",
    "# Encode Sex (Male=1, Female=0)\n",
    "X_encoded['Sex'] = (X_encoded['Sex'] == 'male').astype(int)\n",
    "\n",
    "# Encode Embarked using one-hot encoding\n",
    "X_encoded = pd.get_dummies(X_encoded, columns=['Embarked'], drop_first=True)\n",
    "\n",
    "print('Features after encoding:')\n",
    "print(X_encoded.head())\n",
    "print('\\nFeature columns:', X_encoded.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5bce7b",
   "metadata": {},
   "source": [
    "### 3d. Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb601e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the features\n",
    "X_scaled = scaler.fit_transform(X_encoded)\n",
    "\n",
    "# Convert back to DataFrame to maintain column names\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=X_encoded.columns)\n",
    "\n",
    "print('Features after scaling:')\n",
    "print(X_scaled.head())\n",
    "print('\\nScaling statistics:')\n",
    "print('Mean of scaled features:', X_scaled.mean().round(4).values)\n",
    "print('Std of scaled features:', X_scaled.std().round(4).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0002e9b1",
   "metadata": {},
   "source": [
    "## 4. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725878ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print('Training set size:', X_train.shape)\n",
    "print('Testing set size:', X_test.shape)\n",
    "print('\\nClass distribution in training set:')\n",
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05cc8d0",
   "metadata": {},
   "source": [
    "## 5. Train Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f1d37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the Logistic Regression model\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print('Logistic Regression model trained successfully!')\n",
    "print('Model coefficients:', model.coef_)\n",
    "print('Model intercept:', model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49fbd08",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268ee881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on training and test sets\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy scores\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print('='*60)\n",
    "print('MODEL PERFORMANCE')\n",
    "print('='*60)\n",
    "print(f'Training Accuracy: {train_accuracy:.4f}')\n",
    "print(f'Testing Accuracy: {test_accuracy:.4f}')\n",
    "print('\\n' + '='*60)\n",
    "print('CLASSIFICATION REPORT (Test Set)')\n",
    "print('='*60)\n",
    "print(classification_report(y_test, y_test_pred, target_names=['Did Not Survive', 'Survived']))\n",
    "\n",
    "print('\\n' + '='*60)\n",
    "print('CONFUSION MATRIX (Test Set)')\n",
    "print('='*60)\n",
    "print(confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fc7164",
   "metadata": {},
   "source": [
    "## 7. Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dde315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model using joblib\n",
    "joblib.dump(model, 'titanic_survival_model.pkl')\n",
    "print('✓ Model saved as: titanic_survival_model.pkl')\n",
    "\n",
    "# Save the scaler for preprocessing new data\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "print('✓ Scaler saved as: scaler.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d893ff13",
   "metadata": {},
   "source": [
    "## 8. Load and Test the Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9273a384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "loaded_model = joblib.load('titanic_survival_model.pkl')\n",
    "loaded_scaler = joblib.load('scaler.pkl')\n",
    "\n",
    "print('✓ Model loaded successfully!')\n",
    "print('✓ Scaler loaded successfully!')\n",
    "\n",
    "# Make predictions with the loaded model\n",
    "y_pred_loaded = loaded_model.predict(X_test)\n",
    "loaded_model_accuracy = accuracy_score(y_test, y_pred_loaded)\n",
    "\n",
    "print(f'\\nLoaded Model Test Accuracy: {loaded_model_accuracy:.4f}')\n",
    "print(f'Original Model Test Accuracy: {test_accuracy:.4f}')\n",
    "print(f'Match: {loaded_model_accuracy == test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0ce574",
   "metadata": {},
   "source": [
    "## 9. Example Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02aac400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Make a prediction with a new passenger\n",
    "# Features: Pclass, Sex, Age, Fare, Embarked\n",
    "new_passenger = pd.DataFrame({\n",
    "    'Pclass': [3],\n",
    "    'Sex': ['male'],\n",
    "    'Age': [25],\n",
    "    'Fare': [7.75],\n",
    "    'Embarked': ['S']\n",
    "})\n",
    "\n",
    "# Apply the same preprocessing\n",
    "new_passenger_encoded = new_passenger.copy()\n",
    "new_passenger_encoded['Sex'] = (new_passenger_encoded['Sex'] == 'male').astype(int)\n",
    "new_passenger_encoded = pd.get_dummies(new_passenger_encoded, columns=['Embarked'], drop_first=True)\n",
    "\n",
    "# Ensure all columns match\n",
    "for col in X_encoded.columns:\n",
    "    if col not in new_passenger_encoded.columns:\n",
    "        new_passenger_encoded[col] = 0\n",
    "\n",
    "new_passenger_encoded = new_passenger_encoded[X_encoded.columns]\n",
    "\n",
    "# Scale the features\n",
    "new_passenger_scaled = loaded_scaler.transform(new_passenger_encoded)\n",
    "\n",
    "# Make prediction\n",
    "prediction = loaded_model.predict(new_passenger_scaled)[0]\n",
    "probability = loaded_model.predict_proba(new_passenger_scaled)[0]\n",
    "\n",
    "print('='*60)\n",
    "print('EXAMPLE PREDICTION')\n",
    "print('='*60)\n",
    "print('Passenger Details:')\n",
    "print(f'  Pclass: {new_passenger[\"Pclass\"].values[0]}')\n",
    "print(f'  Sex: {new_passenger[\"Sex\"].values[0]}')\n",
    "print(f'  Age: {new_passenger[\"Age\"].values[0]}')\n",
    "print(f'  Fare: {new_passenger[\"Fare\"].values[0]}')\n",
    "print(f'  Embarked: {new_passenger[\"Embarked\"].values[0]}')\n",
    "print('\\nPrediction Result:')\n",
    "result = 'SURVIVED' if prediction == 1 else 'DID NOT SURVIVE'\n",
    "print(f'  Predicted: {result}')\n",
    "print(f'  Confidence (Did Not Survive): {probability[0]:.4f}')\n",
    "print(f'  Confidence (Survived): {probability[1]:.4f}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
