{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e63b8a32",
   "metadata": {},
   "source": [
    "# Titanic Survival Prediction System\n",
    "## Model Development\n",
    "**Name:** Onafowokan Testament\n",
    "\n",
    "**Matric:** 21cg029905\n",
    "\n",
    "**Algorithm:** Logistic Regression\n",
    "\n",
    "**Features Used:** Pclass, Sex, Age, Fare, Embarked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03053d06",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147c83c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print('All libraries imported successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e95781",
   "metadata": {},
   "source": [
    "## 2. Load the Titanic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc43353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Titanic dataset\n",
    "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "print('Dataset shape:', df.shape)\n",
    "print('\\nFirst few rows:')\n",
    "print(df.head())\n",
    "print('\\nDataset Info:')\n",
    "print(df.info())\n",
    "print('\\nMissing Values:')\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e33d4a5",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987342d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features and target variable\n",
    "features = ['Pclass', 'Sex', 'Age', 'Fare', 'Embarked']\n",
    "X = df[features].copy()\n",
    "y = df['Survived'].copy()\n",
    "\n",
    "print('Selected Features:', features)\n",
    "print('Target Variable: Survived')\n",
    "print('\\nDataset shape - X:', X.shape, 'y:', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43196141",
   "metadata": {},
   "source": [
    "### 3a. Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3e6677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print('Missing values before handling:')\n",
    "print(X.isnull().sum())\n",
    "\n",
    "# Handle missing values\n",
    "# Age: fill with median\n",
    "X['Age'].fillna(X['Age'].median(), inplace=True)\n",
    "\n",
    "# Embarked: fill with mode\n",
    "X['Embarked'].fillna(X['Embarked'].mode()[0], inplace=True)\n",
    "\n",
    "# Fare: fill with median\n",
    "X['Fare'].fillna(X['Fare'].median(), inplace=True)\n",
    "\n",
    "print('\\nMissing values after handling:')\n",
    "print(X.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddc4aed",
   "metadata": {},
   "source": [
    "### 3b & 3c. Encode Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10352737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy for encoding\n",
    "X_encoded = X.copy()\n",
    "\n",
    "# Encode Sex (Male=1, Female=0)\n",
    "X_encoded['Sex'] = (X_encoded['Sex'] == 'male').astype(int)\n",
    "\n",
    "# Encode Embarked using one-hot encoding\n",
    "X_encoded = pd.get_dummies(X_encoded, columns=['Embarked'], drop_first=True)\n",
    "\n",
    "print('Features after encoding:')\n",
    "print(X_encoded.head())\n",
    "print('\\nFeature columns:', X_encoded.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5bce7b",
   "metadata": {},
   "source": [
    "### 3d. Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb601e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the features\n",
    "X_scaled = scaler.fit_transform(X_encoded)\n",
    "\n",
    "# Convert back to DataFrame to maintain column names\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=X_encoded.columns)\n",
    "\n",
    "print('Features after scaling:')\n",
    "print(X_scaled.head())\n",
    "print('\\nScaling statistics:')\n",
    "print('Mean of scaled features:', X_scaled.mean().round(4).values)\n",
    "print('Std of scaled features:', X_scaled.std().round(4).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0002e9b1",
   "metadata": {},
   "source": [
    "## 4. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725878ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print('Training set size:', X_train.shape)\n",
    "print('Testing set size:', X_test.shape)\n",
    "print('\\nClass distribution in training set:')\n",
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05cc8d0",
   "metadata": {},
   "source": [
    "## 5. Train Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f1d37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the Logistic Regression model\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print('Logistic Regression model trained successfully!')\n",
    "print('Model coefficients:', model.coef_)\n",
    "print('Model intercept:', model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49fbd08",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268ee881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on training and test sets\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy scores\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print('='*60)\n",
    "print('MODEL PERFORMANCE')\n",
    "print('='*60)\n",
    "print(f'Training Accuracy: {train_accuracy:.4f}')\n",
    "print(f'Testing Accuracy: {test_accuracy:.4f}')\n",
    "print('\\n' + '='*60)\n",
    "print('CLASSIFICATION REPORT (Test Set)')\n",
    "print('='*60)\n",
    "print(classification_report(y_test, y_test_pred, target_names=['Did Not Survive', 'Survived']))\n",
    "\n",
    "print('\\n' + '='*60)\n",
    "print('CONFUSION MATRIX (Test Set)')\n",
    "print('='*60)\n",
    "print(confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fc7164",
   "metadata": {},
   "source": [
    "## 7. Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dde315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model using joblib\n",
    "joblib.dump(model, 'titanic_survival_model.pkl')\n",
    "print('✓ Model saved as: titanic_survival_model.pkl')\n",
    "\n",
    "# Save the scaler for preprocessing new data\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "print('✓ Scaler saved as: scaler.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d893ff13",
   "metadata": {},
   "source": [
    "## 8. Load and Test the Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9273a384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "loaded_model = joblib.load('titanic_survival_model.pkl')\n",
    "loaded_scaler = joblib.load('scaler.pkl')\n",
    "\n",
    "print('✓ Model loaded successfully!')\n",
    "print('✓ Scaler loaded successfully!')\n",
    "\n",
    "# Make predictions with the loaded model\n",
    "y_pred_loaded = loaded_model.predict(X_test)\n",
    "loaded_model_accuracy = accuracy_score(y_test, y_pred_loaded)\n",
    "\n",
    "print(f'\\nLoaded Model Test Accuracy: {loaded_model_accuracy:.4f}')\n",
    "print(f'Original Model Test Accuracy: {test_accuracy:.4f}')\n",
    "print(f'Match: {loaded_model_accuracy == test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0ce574",
   "metadata": {},
   "source": [
    "## 9. Example Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02aac400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Make a prediction with a new passenger\n",
    "# Features: Pclass, Sex, Age, Fare, Embarked\n",
    "new_passenger = pd.DataFrame({\n",
    "    'Pclass': [3],\n",
    "    'Sex': ['male'],\n",
    "    'Age': [25],\n",
    "    'Fare': [7.75],\n",
    "    'Embarked': ['S']\n",
    "})\n",
    "\n",
    "# Apply the same preprocessing\n",
    "new_passenger_encoded = new_passenger.copy()\n",
    "new_passenger_encoded['Sex'] = (new_passenger_encoded['Sex'] == 'male').astype(int)\n",
    "new_passenger_encoded = pd.get_dummies(new_passenger_encoded, columns=['Embarked'], drop_first=True)\n",
    "\n",
    "# Ensure all columns match\n",
    "for col in X_encoded.columns:\n",
    "    if col not in new_passenger_encoded.columns:\n",
    "        new_passenger_encoded[col] = 0\n",
    "\n",
    "new_passenger_encoded = new_passenger_encoded[X_encoded.columns]\n",
    "\n",
    "# Scale the features\n",
    "new_passenger_scaled = loaded_scaler.transform(new_passenger_encoded)\n",
    "\n",
    "# Make prediction\n",
    "prediction = loaded_model.predict(new_passenger_scaled)[0]\n",
    "probability = loaded_model.predict_proba(new_passenger_scaled)[0]\n",
    "\n",
    "print('='*60)\n",
    "print('EXAMPLE PREDICTION')\n",
    "print('='*60)\n",
    "print('Passenger Details:')\n",
    "print(f'  Pclass: {new_passenger[\"Pclass\"].values[0]}')\n",
    "print(f'  Sex: {new_passenger[\"Sex\"].values[0]}')\n",
    "print(f'  Age: {new_passenger[\"Age\"].values[0]}')\n",
    "print(f'  Fare: {new_passenger[\"Fare\"].values[0]}')\n",
    "print(f'  Embarked: {new_passenger[\"Embarked\"].values[0]}')\n",
    "print('\\nPrediction Result:')\n",
    "result = 'SURVIVED' if prediction == 1 else 'DID NOT SURVIVE'\n",
    "print(f'  Predicted: {result}')\n",
    "print(f'  Confidence (Did Not Survive): {probability[0]:.4f}')\n",
    "print(f'  Confidence (Survived): {probability[1]:.4f}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
